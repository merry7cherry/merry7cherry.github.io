{
  "publications": [
    {
      "id": "cad-vae",
      "title": "CAD-VAE: Leveraging Correlation-Aware Latents for Comprehensive Fair Disentanglement",
      "authors": [
        "Chenrui Ma",
        "Xi Xiao",
        "Tianyang Wang",
        "Xiao Wang",
        "Yanning Shen"
      ],
      "venue": "AAAI",
      "year": "2026",
      "image": "img/papers/cad-vae.png",
      "arxiv_id": "2503.07938",
      "github_repo": "merry7cherry/CAD-VAE",
      "links": {
        "arxiv": "https://arxiv.org/abs/2503.07938",
        "code": "https://github.com/merry7cherry/CAD-VAE"
      },
      "selected": true,
      "tldr": "CAD-VAE leverages a Correlation-Aware latent code to model the correlation between target and sensitive attributes so that achieving comprehensive Fair Disentanglement",
      "github_stars": 2,
      "citations": 5
    },
    {
      "id": "stochastic-interpolants",
      "title": "Stochastic Interpolants via Conditional Dependent Coupling",
      "authors": [
        "Chenrui Ma",
        "Xi Xiao",
        "Tianyang Wang",
        "Xiao Wang",
        "Yanning Shen"
      ],
      "venue": "ICLR (Submitted)",
      "year": "2026",
      "image": "img/papers/stochastic-interpolants.png",
      "arxiv_id": "2509.23122",
      "github_repo": "merry7cherry/Stochastic-Interpolants-via-Conditional-Dependent-Coupling",
      "links": {
        "arxiv": "https://arxiv.org/abs/2509.23122",
        "code": "https://github.com/merry7cherry/Stochastic-Interpolants-via-Conditional-Dependent-Coupling"
      },
      "selected": true,
      "tldr": "Stochastic Interpolants via Conditional Dependent Coupling is a simple, efficient and novel multi-stage generative framework for coarse-to-fine image generation. The single generative model prameterizes all stages of the generative process, and can be trained in an end-to-end manner.",
      "github_stars": 1,
      "citations": 3
    },
    {
      "id": "learning-straight-flows",
      "title": "Learning Straight Flows: Variational Flow Matching for Efficient Generation",
      "authors": [
        "Chenrui Ma",
        "Xi Xiao",
        "Tianyang Wang",
        "Xiao Wang",
        "Yanning Shen"
      ],
      "venue": "CVPR (Submitted)",
      "year": "2026",
      "image": "img/papers/learning-straight-flows.png",
      "arxiv_id": "2511.17583",
      "github_repo": "merry7cherry/S-VFM",
      "links": {
        "arxiv": "https://arxiv.org/abs/2511.17583",
        "code": "https://github.com/merry7cherry/S-VFM"
      },
      "selected": true,
      "tldr": "Introduing a varitional latent code, which provides \"generation overview\", and the straightness loss into flow matching framework for efficient (one-step) image generation.",
      "github_stars": 0,
      "citations": 2
    },
    {
      "id": "probe",
      "title": "Self-Supervised Visual Prompting for Cross-Domain Road Damage Detection",
      "authors": [
        "Xi Xiao",
        "Zhuxuanzi Wang",
        "Mingqiao Mo",
        "Chen Liu",
        "Chenrui Ma",
        "Yanshu Li",
        "Smita Krishnaswamy",
        "Xiao Wang",
        "Tianyang Wang"
      ],
      "venue": "WACV",
      "year": "2026",
      "image": "img/papers/probe.png",
      "arxiv_id": "2511.12410",
      "github_repo": "xixiaouab/PROBE",
      "links": {
        "arxiv": "https://arxiv.org/abs/2511.12410",
        "code": "https://github.com/xixiaouab/PROBE"
      },
      "selected": true,
      "tldr": "This work introduces a self-supervised framework that uses defect-aware prompts to probe unlabeled target domains, enabling robust cross-domain pavement defect detection without costly re-annotation. The method achieves strong zero-shot transfer and outperforms supervised, self-supervised, and adaptation baselines across multiple benchmarks.",
      "github_stars": 0,
      "citations": 0
    },
    {
      "id": "cibr",
      "title": "CIBR: Cross-modal information bottleneck regularization for robust clip generalization",
      "authors": [
        "Yingrui Ji",
        "Xi Xiao",
        "Gaofei Chen",
        "Hao Xu",
        "Chenrui Ma",
        "Lijing Zhu",
        "Aokun Liang",
        "Jiansheng Chen"
      ],
      "venue": "ICANN",
      "year": "2025",
      "image": "img/papers/cibr.png",
      "links": {
        "arxiv": "https://link.springer.com/chapter/10.1007/978-3-032-04558-4_20"
      },
      "selected": true,
      "tldr": "This work explains CLIPâ€™s generalization using an Information Bottleneck view and introduces a regularization method (CIBR) that reduces modality-specific redundancy, yielding consistent performance improvements.",
      "citations": 0
    },
    {
      "id": "beyond-editing-pairs",
      "title": "Beyond Editing Pairs: Fine-Grained Instructional Image Editing via Multi-Scale Learnable Regions",
      "authors": [
        "Chenrui Ma",
        "Xi Xiao",
        "Tianyang Wang",
        "Yanning Shen"
      ],
      "venue": "Revising...",
      "year": "2025",
      "image": "img/papers/beyond-editing-pairs.png",
      "arxiv_id": "2505.19352",
      "links": {
        "arxiv": "https://arxiv.org/abs/2505.19352"
      },
      "selected": true,
      "tldr": "Leveraging the representational strength of unified encoders (e.g., CLIP) and combine it with pretrained diffusion models to achieve fine-grained image editing via a learnable region",
      "citations": 4
    },
    {
      "id": "ctr-lora",
      "title": "CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models",
      "authors": [
        "Zhuxuanzi Wang",
        "Mingqiao Mo",
        "Xi Xiao",
        "Chen Liu",
        "Chenrui Ma",
        "Yunbei Zhang",
        "Xiao Wang",
        "Smita Krishnaswamy",
        "Tianyang Wang"
      ],
      "venue": "ICASSP (Submitted)",
      "year": "2026",
      "arxiv_id": "2510.15962",
      "links": {
        "arxiv": "https://arxiv.org/abs/2510.15962"
      },
      "selected": false,
      "tldr": "CTR-LoRA is a simple and efficient LoRA framework for large language models. It is based on the idea of using a simple and efficient LoRA framework for large language models.",
      "citations": 0
    }
  ]
}